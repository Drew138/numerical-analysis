{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cardiac-novelty",
   "metadata": {},
   "source": [
    "# Big Matrix Multiplication and Its Applications"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "immune-savage",
   "metadata": {},
   "source": [
    "# Table of Contents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "affiliated-processing",
   "metadata": {},
   "source": [
    "# Abstract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "skilled-coast",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "taken-anatomy",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "Given two matrices $A$ and $B$, each with $n$ rows and columns. Matrix multiplication is defined as the result of the dot product of every $ith$ row of matrix $A$ by each $jth$ column of matrix $B$. This operation yields a new matrix of $n^2$ dimmensions, where the $ijth$ position contains the product of the computations previously described.\n",
    "\n",
    "Common use cases for this kind of operation are:\n",
    "\n",
    "* Solving systems of linear equations.\n",
    "* Solving intricate graph problems.\n",
    "* Representing the logic gates applied over a quantum system.\n",
    "* Applying rotations to projected objects in a 3D plane (Computer Graphics).\n",
    "\n",
    "Among many others.\n",
    "\n",
    "Despite being an extremely useful operation, it regretably can not be used in every desired scenario.<br/> \n",
    "Due to the nature of the operations required to calculate the resulting matrix. Cases where we deal with matrixes of great dimmensions rapidly become unfeasible, leaving a vast amount of problems unsolved. For this reason, it is always important to use efficient methods when dealing with great ammounts of data.\n",
    "\n",
    "Merely reading, and writing operations of matrices take $O(n^2)$ time and space, setting a hard cap of $O(n^2)$ for any implementation of an algorithm aiming to do matrix multiplication. Nonetheless, in reality it is much worse, since time complexities for most algorithms range from approximately $O(n^{2.5})$ to $O(n^3)$. Because of this some algorithms also try to leverage parallelism in order speed up operations. However, improvements in performance do not increase a lot from there.\n",
    "\n",
    "In this paper we will be analyzing various matrix multiplication algorithms, the logic behind them, and their performance in benchmarks using various programming languages."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "surrounded-punishment",
   "metadata": {},
   "source": [
    "# Objectives"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "positive-algorithm",
   "metadata": {},
   "source": [
    "* Describe the pros and cons of each matrix multiplication method.\n",
    "* Compare the performance of each algorithm given an increase in the input size."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "welcome-signal",
   "metadata": {},
   "source": [
    "# Algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "federal-newspaper",
   "metadata": {},
   "source": [
    "Matrix multiplication have several implementations, some being more favorable certain problems, others being applicable to only certain types of matrices. For the purpose of narrowing down our analysis, we will be focusing on three specific algorithms: \n",
    "\n",
    "1. Naive Algorithm\n",
    "2. Strassens Algorithm\n",
    "3. GEMM Algorithm\n",
    "\n",
    "While there are plenty of other algorithms that could arguably achieve a better performance than these, they were not selected because they were either theoretical algorithms, or too intricate to be analyzed in this paper.\n",
    "\n",
    "In the following section we will be display a brief overview of each of the selected algorithms."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "exclusive-dayton",
   "metadata": {},
   "source": [
    "## Naive Method"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "naughty-unknown",
   "metadata": {},
   "source": [
    "Probably the simplest among all multiplication algorithms. It performs the inner product of each row by each column without any optimizations or caches. For square matrices, it's time complexity is considered to be $O(n^3)$  \n",
    "\n",
    "Pseudo Code:\n",
    "<br/>Pros:<br/>\n",
    "`* Algorithm is easy to understand and implement.`\n",
    "<br/>Cons:<br/>\n",
    "`* $O(n^3)$ which becomes computationally prohibitive for big matrices.`\n",
    "\n",
    "\n",
    "<img align=\"left\" width=\"700px\" src=\"assets/matrix_multiplications.png\">\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "architectural-helmet",
   "metadata": {},
   "source": [
    "## Strassens Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bulgarian-aruba",
   "metadata": {},
   "outputs": [],
   "source": [
    "https://www.baeldung.com/cs/matrix-multiplication-algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "saved-probability",
   "metadata": {},
   "source": [
    "## GEMM Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "strange-protest",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "metallic-israel",
   "metadata": {},
   "outputs": [],
   "source": [
    "def traditional(matrix_one, matrix_two):\n",
    "    if len(matrix_one[0]) != len(matrix_two):\n",
    "        raise Exception(\"Matrix_one row size doesn't coincide with matrix_two column size\")\n",
    "    answer = [[0 for _ in range(len(matrix_one[0]))] * len(matrix_two)]\n",
    "    for i in range(matrix_one[0]):\n",
    "        for j in range(matrix_two):\n",
    "            for k in range(len(matrix_one[0])):\n",
    "                answer[i][j] += matrix_one[i][k] * matrix_two[k][j]\n",
    "    return answer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "intended-region",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def recordTime(y_axis, x_axis, func, *args, **kwargs):\n",
    "    initial = time.now()\n",
    "    func(*args, **kwargs)\n",
    "    total = time.now() - initial\n",
    "    \n",
    "def generateMatrixes():\n",
    "    pass\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "graphic-wealth",
   "metadata": {},
   "source": [
    "# Programming Languages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exceptional-athletics",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "reasonable-brain",
   "metadata": {},
   "source": [
    "# Benchmarks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "extended-court",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "driven-participant",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "sixth-workplace",
   "metadata": {},
   "source": [
    "# Conclusions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "twelve-state",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "orange-dominant",
   "metadata": {},
   "source": [
    "# Bibliography"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "featured-public",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
